Transferring dexterous grasps to novel objects is a challenging problem. One approach is to machine learn solutions with techniques able to perform powerful generalisation. Another is to use an underactuated hand to cope with shape variation. In this paper we combine the benefits of both approaches by learning grasps for underactuated hands. Underactuated hands exploit the contacts that occur during grasping to achieve a wide variety of final grasp configurations. The final grasp configuration depends not only on the final hand pose, but also on the object shape, and on the reach to grasp trajectory. An interesting challenge is to use machine learning to exploit these interactions. The key technical challenge in applying machine learning to grasping with underactuated hands is to learn the right trajectory for a particular object shape so as to achieve a good grasp of a particular type. 

One approach would be to learn the typical contact interactions that occur during a grasp, and to generate new grasps that reproduce these. The contact interactions are, however, rather complex and variable, even given small variations in object shape and friction. Therefore we tackle the problem by implicitly encoding the contact interactions in terms of the approach trajectory. Our method learns both the desired final contacts, the final hand shape, and possible sequences of hand pose during the reach to grasp trajectory. We build on our previous work on one-shot learning of grasps that transfer to novel objects, employing a product of experts. The novel technical contribution is that in this paper we show how to learn not only final grasp, but also the approach trajectory and control strategy for closing the dexterous hand. In particular we learn a bundle of multiple trajectories that will all likely lead to a similar final stable grasp. We enable this by learning from examples generated in a rigid body physics simulation. Finally at the grasp selection stage we now optimise across a space defined by this bundle of approach trajectories so as to maximise the chance of reaching a stable grasp. The method copes with partial and noisy shape information for the test objects. The method also requires no knowledge of the human defined object category, either when learning or performing transfer.

% SUBSECTION BETTER?
\subsection{RELATED WORK}
Previous work in learning generalisable grasps falls broadly into two classes. One class of approaches utilises the shape of common object parts or their appearance to generalise grasps across object categories \cite{saxena2008b,detry2013a,herzog2014a, kroemer2012a}. This works well for low DoF hands. Another class of approaches captures the global properties of the hand shape either at the point of grasping, or during the approach \cite{ben2012generalization}. This global hand shape can additionally be associated with global object shape, allowing generalisation by warping grasps to match warps of global object shape \cite{hillenbrand2012transferring}. This second class works well for high DoF hands, but generalisation is more limited. We have previously achieved the advantages of both classes, generalising grasps across object categories with high DoF hands. In this paper we go beyond this, learning and generalising grasps for under-actuated hands.

Several hands with such behavior have been proposed in the literature with different implementations~\cite{Catalano2014Adaptive, Dollar2010Highly}, with a common goal: simplicity and robustness. Their usage testbed examples are promising, however, autonomous grasps faces with quite new challenges due to the almost-null observability of the finger deformation when the hand is constrained by the environment and objects. Most of the planning algorithms for this type of hands boil down to generate good wrist poses and let the adaptive mechanism do its job while closing, such as~\cite{Eppner2015Planning}, where a sequence of wrist and object poses and the corresponing wrench of interaction is generated, that are expected to exploit environmental constraints. Another approach is that by~\cite{Bonilla2014Grasping,Bonilla2015Grasp}, where static wrist poses are sampled using different strategies around the object from where the fingers are closed using a rigid-body simulator, to finally select the areas of major success rate to generate new wrist poses.

While these approaches makes sense, since that is the purpose of the adaptive mechanism, we believe that learning how the adaptation takes place after the mechanism has been deformed can aid a more sophisticated planner to reason about what could be a desired hand shape when following a wrist trajectory given an environment.